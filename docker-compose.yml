version: '3.8' # Эта строка опциональна для современных версий Docker Compose

services:
  # --- База Данных для Результатов Работы Пайплайна ---
  postgres_results_db_service: # Переименовали из postgres_db для ясности
    image: postgres:15
    container_name: postgres_results_db_service
    environment:
      POSTGRES_DB: ${DB_NAME}       # Для постов и саммари
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    volumes:
      - postgres_results_data:/var/lib/postgresql/data
    ports:
      - "${DB_PORT_RESULTS:-5433}:5432" # Используем DB_PORT_RESULTS из .env или 5433 по умолчанию
    networks:
      - app-network
    healthcheck: # Добавляем healthcheck
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER} -d ${DB_NAME}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # === Сервисы Apache Airflow ===

  # --- База Данных для Метаданных Airflow ---
  postgres_airflow_db:
    image: postgres:15
    container_name: postgres_airflow_db_service
    environment:
      POSTGRES_DB: ${AIRFLOW_DB_NAME}
      POSTGRES_USER: ${AIRFLOW_DB_USER}
      POSTGRES_PASSWORD: ${AIRFLOW_DB_PASSWORD}
    volumes:
      - postgres_airflow_data:/var/lib/postgresql/data
    ports:
      - "${AIRFLOW_DB_PORT_ON_HOST:-5434}:5432" # Порт для Airflow БД, если нужен внешний доступ
    networks:
      - app-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${AIRFLOW_DB_USER} -d ${AIRFLOW_DB_NAME}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # --- Инициализация Airflow (Запускается один раз для создания/миграции БД и пользователя) ---
  # Этот сервис выполняет 'airflow db migrate' и 'airflow users create'
  # Он должен запускаться ПЕРЕД scheduler и webserver
  airflow-init:
    image: apache/airflow:${AIRFLOW_IMAGE_TAG:-2.8.4} # Используй актуальную версию
    container_name: airflow_init_service
    depends_on:
      postgres_airflow_db:
        condition: service_healthy # Ждет, пока БД Airflow будет готова
    env_file:
      - .env
    entrypoint: /bin/bash # Переопределяем entrypoint для выполнения нескольких команд
    command:
      - -c
      - |
        set -e;
        if [ ! -f "/opt/airflow/airflow_initialized.flag" ]; then
          echo "Инициализация/Миграция базы данных Airflow...";
          airflow db migrate;
          echo "Создание пользователя Admin Airflow (если не существует)...";
          airflow users create \
            --username ${_AIRFLOW_WWW_USER_USERNAME:-admin} \
            --firstname Admin \
            --lastname User \
            --role Admin \
            --email admin@example.com \
            --password ${_AIRFLOW_WWW_USER_PASSWORD:-admin};
          touch /opt/airflow/airflow_initialized.flag;
          echo "Инициализация Airflow завершена.";
        else
          echo "Airflow уже был инициализирован.";
        fi
    volumes:
      # Том для флага инициализации, чтобы команда не выполнялась каждый раз
      - airflow_init_flag_volume:/opt/airflow 
    networks:
      - app-network
    # Этот сервис не должен перезапускаться, он выполняет задачу и выходит
    # restart: "no" # Docker Compose v2.1+ или можно просто не указывать

  # --- Airflow Scheduler ---
  airflow-scheduler:
    image: apache/airflow:${AIRFLOW_IMAGE_TAG:-2.8.4} # Убедись, что версия та же, что и у init/webserver
    container_name: airflow_scheduler_service
    depends_on:
      airflow-init: # Ждет завершения инициализации
        condition: service_completed_successfully # Для сервисов, которые должны завершиться
      postgres_airflow_db: # Также явно зависит от БД
        condition: service_healthy
    env_file:
      - .env
    user: "${AIRFLOW_UID:-50000}:0" # UID:GID, GID 0 = root
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./config:/opt/airflow/config # <-- Монтируем папку config
      # Монтируем Docker socket для DockerOperator
      - /var/run/docker.sock:/var/run/docker.sock
    command: scheduler
    networks:
      - app-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "airflow jobs check --job-type SchedulerJob --hostname $(hostname) --local"]
      interval: 30s
      timeout: 30s
      retries: 5

  # --- Airflow Webserver ---
  airflow-webserver:
    image: apache/airflow:${AIRFLOW_IMAGE_TAG:-2.8.4}
    container_name: airflow_webserver_service
    depends_on:
      airflow-scheduler: # Ждет, пока планировщик будет здоров
        condition: service_healthy
    env_file:
      - .env
    user: "${AIRFLOW_UID:-50000}:0"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./config:/opt/airflow/config # <-- Монтируем папку config
      # Монтируем Docker socket для DockerOperator (например, для теста задач из UI)
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - "${AIRFLOW_WEB_PORT:-8080}:8080" # Порт для UI Airflow
    command: webserver
    networks:
      - app-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8080/health"]
      interval: 30s # Увеличено, так как веб-сервер может дольше стартовать
      timeout: 10s
      retries: 5

  # Сервисы parser и summarizer УДАЛЕНЫ, так как их логика будет запускаться через Airflow DockerOperator

volumes:
  postgres_results_data:
  postgres_airflow_data:
  airflow_init_flag_volume: # Том для хранения флага, что инициализация Airflow прошла

networks:
  app-network:
    driver: bridge
    name: mlops_project_app_net # Явно задаем имя сети для предсказуемости