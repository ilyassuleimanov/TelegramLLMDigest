version: '3.8' # Эта строка опциональна для современных версий Docker Compose

services:
  # --- База Данных для Результатов Работы Пайплайна ---
  postgres_results_db_service: 
    image: postgres:15
    container_name: postgres_results_db_service
    environment:
      POSTGRES_DB: ${DB_NAME}       # Для постов и саммари
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    volumes:
      - postgres_results_data:/var/lib/postgresql/data
    ports:
      - "${DB_PORT_RESULTS_ON_HOST}:5432" 
    networks:
      - app-network
    healthcheck: # Добавляем healthcheck
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER} -d ${DB_NAME}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # === Сервисы Apache Airflow ===

  # --- База Данных для Метаданных Airflow ---
  postgres_airflow_db:
    image: postgres:15
    container_name: postgres_airflow_db_service
    environment:
      POSTGRES_DB: ${AIRFLOW_DB_NAME}
      POSTGRES_USER: ${AIRFLOW_DB_USER}
      POSTGRES_PASSWORD: ${AIRFLOW_DB_PASSWORD}
    volumes:
      - postgres_airflow_data:/var/lib/postgresql/data
    ports:
      - "${AIRFLOW_DB_PORT_ON_HOST}:5432" # Порт для Airflow БД, если нужен внешний доступ
    networks:
      - app-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${AIRFLOW_DB_USER} -d ${AIRFLOW_DB_NAME}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # --- Инициализация Airflow (Запускается один раз для создания/миграции БД и пользователя) ---
  # Этот сервис выполняет 'airflow db migrate' и 'airflow users create'
  # Он должен запускаться ПЕРЕД scheduler и webserver
  airflow-init:
    image: apache/airflow:${AIRFLOW_IMAGE_TAG} # Используй актуальную версию
    container_name: airflow_init_service
    depends_on:
      postgres_airflow_db:
        condition: service_healthy # Ждет, пока БД Airflow будет готова
    env_file:
      - .env
    entrypoint: /bin/bash # Переопределяем entrypoint для выполнения нескольких команд
    command:
      - -c
      - |
        set -e;
        if [ ! -f "/opt/airflow/airflow_initialized.flag" ]; then
          echo "Инициализация/Миграция базы данных Airflow...";
          airflow db migrate;
          echo "Создание пользователя Admin Airflow (если не существует)...";
          airflow users create \
            --username ${_AIRFLOW_WWW_USER_USERNAME:-admin} \
            --firstname Admin \
            --lastname User \
            --role Admin \
            --email admin@example.com \
            --password ${_AIRFLOW_WWW_USER_PASSWORD:-admin};
          touch /opt/airflow/airflow_initialized.flag;
          echo "Инициализация Airflow завершена.";
        else
          echo "Airflow уже был инициализирован.";
        fi
    volumes:
      # Том для флага инициализации, чтобы команда не выполнялась каждый раз
      - airflow_init_flag_volume:/opt/airflow 
    networks:
      - app-network
    # Этот сервис не должен перезапускаться, он выполняет задачу и выходит
    # restart: "no" # Docker Compose v2.1+ или можно просто не указывать

  # --- Airflow Scheduler ---
  airflow-scheduler:
    image: apache/airflow:${AIRFLOW_IMAGE_TAG} # Убедись, что версия та же, что и у init/webserver
    container_name: airflow_scheduler_service
    depends_on:
      airflow-init: # Ждет завершения инициализации
        condition: service_completed_successfully # Для сервисов, которые должны завершиться
      postgres_airflow_db: # Также явно зависит от БД
        condition: service_healthy
    env_file:
      - .env
    user: "${AIRFLOW_UID}:0" # UID:GID, GID 0 = root
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./config:/opt/airflow/config # <-- Монтируем папку config
      # Монтируем Docker socket для DockerOperator
      - /var/run/docker.sock:/var/run/docker.sock
    command: scheduler
    networks:
      - app-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "airflow jobs check --job-type SchedulerJob --local"]
      interval: 30s
      timeout: 30s
      retries: 5

  # --- Airflow Webserver ---
  airflow-webserver:
    image: apache/airflow:${AIRFLOW_IMAGE_TAG}
    container_name: airflow_webserver_service
    depends_on:
      airflow-scheduler: # Ждет, пока планировщик будет здоров
        condition: service_healthy
    env_file:
      - .env
    user: "${AIRFLOW_UID}:0"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./config:/opt/airflow/config # <-- Монтируем папку config
      # Монтируем Docker socket для DockerOperator (например, для теста задач из UI)
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - "${AIRFLOW_WEB_PORT:-8080}:8080" # Порт для UI Airflow
    command: webserver
    networks:
      - app-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8080/health"]
      interval: 30s # Увеличено, так как веб-сервер может дольше стартовать
      timeout: 10s
      retries: 5

  # === API Сервис для Результатов ===
  fastapi_service:
    build:
      context: ./fastAPI_app # Путь к папке с Dockerfile и кодом FastAPI
      dockerfile: Dockerfile
    container_name: fastapi_api_service # Даем понятное имя контейнеру
    env_file:
      - .env # Подтягиваем все переменные из .env файла
    environment:
      # Явно передаем переменные, которые main.py ожидает,
      # используя значения из .env (Docker Compose автоматически их подставит)
      # или напрямую задавая их, если они отличаются от тех, что в .env
      CHANNELS_FILE_PATH: ${CHANNELS_FILE_PATH_IN_CONTAINER} # Путь ВНУТРИ контейнера FastAPI
      DB_HOST: ${DB_HOST} # Имя сервиса БД результатов
      DB_PORT: ${DB_PORT} # Внутренний порт контейнера PostgreSQL
      DB_USER: ${DB_USER} # Используем те же, что для postgres_results_db_service
      DB_PASSWORD: ${DB_PASSWORD} # Используем те же, что для postgres_results_db_service
      DB_NAME: ${DB_NAME} # Используем те же, что для postgres_results_db_service
    volumes:
      # Монтируем файл channels.json с хоста в контейнер
      - ${CHANNELS_CONFIG_FILE_ON_HOST}:${CHANNELS_FILE_PATH_IN_CONTAINER}:ro # ro = read-only
      # Для разработки с --reload можно смонтировать весь код приложения
      - ./fastAPI_app:/app # Код FastAPI монтируется в /app (где WORKDIR в Dockerfile)
    ports:
      - "${FASTAPI_PORT_ON_HOST:-8000}:8000" # Пробрасываем порт FastAPI на хост
    networks:
      - app-network # Используем ту же сеть, что и другие сервисы
    depends_on:
      postgres_results_db_service: # FastAPI зависит от базы данных результатов
        condition: service_healthy # Ждет, пока БД будет готова
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8000/docs || exit 1"] # Проверяем доступность Swagger UI
      interval: 30s
      timeout: 10s
      retries: 5

volumes:
  postgres_results_data:
  postgres_airflow_data:
  airflow_init_flag_volume: # Том для хранения флага, что инициализация Airflow прошла

networks:
  app-network:
    driver: bridge
    name: mlops_project_app_net # Явно задаем имя сети для предсказуемости