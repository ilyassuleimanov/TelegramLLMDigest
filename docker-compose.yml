version: '3.8'

services:
  # БД для результатов работы пайплайна. Для постов и их саммари
  postgres_results_db_service: 
    image: postgres:15
    container_name: postgres_results_db_service
    environment:
      POSTGRES_DB: ${DB_NAME}
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    volumes:
      - postgres_results_data:/var/lib/postgresql/data
    ports:
      - "${DB_PORT_RESULTS_ON_HOST}:5432" 
    networks:
      - app-network
    healthcheck: # Добавляем healthcheck
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER} -d ${DB_NAME}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # Сервисы Airflow

  # БД для метаданных Airflow
  postgres_airflow_db:
    image: postgres:15
    container_name: postgres_airflow_db_service
    environment:
      POSTGRES_DB: ${AIRFLOW_DB_NAME}
      POSTGRES_USER: ${AIRFLOW_DB_USER}
      POSTGRES_PASSWORD: ${AIRFLOW_DB_PASSWORD}
    volumes:
      - postgres_airflow_data:/var/lib/postgresql/data
    ports:
      - "${AIRFLOW_DB_PORT_ON_HOST}:5432" # Порт для Airflow БД
    networks:
      - app-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${AIRFLOW_DB_USER} -d ${AIRFLOW_DB_NAME}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # Инициализация Airflow (Запускается один раз для создания/миграции БД и пользователя)
  # Этот сервис выполняет 'airflow db migrate' и 'airflow users create'
  # Он должен запускаться перед scheduler и webserver
  airflow-init:
    image: apache/airflow:${AIRFLOW_IMAGE_TAG}
    container_name: airflow_init_service
    depends_on:
      postgres_airflow_db:
        condition: service_healthy # Ждет, пока БД Airflow будет готова
    env_file:
      - .env
    entrypoint: /bin/bash # Переопределяем entrypoint для выполнения нескольких команд
    command:
      - -c
      - |
        set -e;
        if [ ! -f "/opt/airflow/airflow_initialized.flag" ]; then
          echo "Инициализация/Миграция базы данных Airflow...";
          airflow db migrate;
          echo "Создание пользователя Admin Airflow (если не существует)...";
          airflow users create \
            --username ${_AIRFLOW_WWW_USER_USERNAME:-admin} \
            --firstname Admin \
            --lastname User \
            --role Admin \
            --email admin@example.com \
            --password ${_AIRFLOW_WWW_USER_PASSWORD:-admin};
          touch /opt/airflow/airflow_initialized.flag;
          echo "Инициализация Airflow завершена.";
        else
          echo "Airflow уже был инициализирован.";
        fi
    volumes:
      # Том для флага инициализации, чтобы команда не выполнялась каждый раз
      - airflow_init_flag_volume:/opt/airflow 
    networks:
      - app-network

  # Airflow Scheduler
  airflow-scheduler:
    image: apache/airflow:${AIRFLOW_IMAGE_TAG}
    container_name: airflow_scheduler_service
    depends_on:
      airflow-init: # Ждет завершения инициализации
        condition: service_completed_successfully # Для сервисов, которые должны завершиться
      postgres_airflow_db: # Также зависит от БД
        condition: service_healthy
    env_file:
      - .env
    user: "${AIRFLOW_UID}:0" # UID:GID
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./config:/opt/airflow/config # Монтируем папку config
      # Монтируем Docker socket для DockerOperator
      - /var/run/docker.sock:/var/run/docker.sock
    command: scheduler
    networks:
      - app-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "airflow jobs check --job-type SchedulerJob --local"]
      interval: 30s
      timeout: 30s
      retries: 5

  # Airflow Webserver
  airflow-webserver:
    image: apache/airflow:${AIRFLOW_IMAGE_TAG}
    container_name: airflow_webserver_service
    depends_on:
      airflow-scheduler: # Ждет, пока планировщик будет healthy
        condition: service_healthy
    env_file:
      - .env
    user: "${AIRFLOW_UID}:0"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./config:/opt/airflow/config # <-- Монтируем папку config
      # Монтируем Docker socket для DockerOperator
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - "${AIRFLOW_WEB_PORT:-8080}:8080" # Порт для UI Airflow
    command: webserver
    networks:
      - app-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  # API Сервис для Результатов
  fastapi_service:
    build:
      context: ./fastAPI_app # Путь к папке с Dockerfile и кодом FastAPI
      dockerfile: Dockerfile
    container_name: fastapi_api_service
    env_file:
      - .env # Подтягиваем все переменные из .env файла
    environment:
      # Описания переменных в .env файле
      CHANNELS_FILE_PATH: ${CHANNELS_FILE_PATH_IN_CONTAINER}
      DB_HOST: ${DB_HOST}
      DB_PORT: ${DB_PORT}
      DB_USER: ${DB_USER}
      DB_PASSWORD: ${DB_PASSWORD}
      DB_NAME: ${DB_NAME}
    volumes:
      # Монтируем файл channels.json с хоста в контейнер
      - ${CHANNELS_CONFIG_FILE_ON_HOST}:${CHANNELS_FILE_PATH_IN_CONTAINER}:ro # ro = read-only
      - ./fastAPI_app:/app # Код FastAPI монтируется в WORKDIR из Dockerfile
    ports:
      - "${FASTAPI_PORT_ON_HOST:-8000}:8000" # Пробрасываем порт FastAPI на хост
    networks:
      - app-network
    depends_on:
      postgres_results_db_service:
        condition: service_healthy # Ждет, пока БД будет healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8000/docs || exit 1"] # Проверяем доступность Swagger UI
      interval: 30s
      timeout: 10s
      retries: 5

  streamlit_service:
    build:
      context: ./streamlit_app # Путь к папке с Dockerfile и кодом Streamlit
      dockerfile: Dockerfile
    container_name: streamlit_ui_service
    env_file:
      - .env # Подтягиваем переменные из .env
    environment:
      FASTAPI_BASE_URL: ${FASTAPI_BASE_URL}
    ports:
      - "${STREAMLIT_PORT_ON_HOST}:8501" # Пробрасываем порт Streamlit на хост
    networks:
      - app-network
    depends_on:
      fastapi_service:
        condition: service_healthy # Ждет, пока FastAPI будет healthy
    restart: unless-stopped

volumes:
  postgres_results_data:
  postgres_airflow_data:
  airflow_init_flag_volume: # Том для хранения флага, что инициализация Airflow прошла

networks:
  app-network:
    driver: bridge
    name: mlops_project_app_net # Явно задаем имя сети