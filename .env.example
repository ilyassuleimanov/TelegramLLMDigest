# ==============================================================================
#                   ПРИМЕР ФАЙЛА ПЕРЕМЕННЫХ ОКРУЖЕНИЯ
# ==============================================================================
# Скопируйте этот файл в .env и заполните СВОИМИ значениями.
# ==============================================================================

# --- Telegram Client Configuration ---
# Используется парсером telegram_parser.py для аутентификации в Telegram API.
# Получить с my.telegram.org
TELEGRAM_API_ID=YOUR_TELEGRAM_API_ID_HERE
TELEGRAM_API_HASH=YOUR_TELEGRAM_API_HASH_HERE
# Номер телефона (в международном формате, например +79012345678), если сессия не найдена
# и требуется первоначальная аутентификация.
# Если файл сессии (TELEGRAM_SESSION_NAME.session) уже существует, можно оставить пустым.
TELEGRAM_PHONE=
# Имя файла сессии Telegram (без расширения .session). Используется парсером.
TELEGRAM_SESSION_NAME=my_telegram_session
# Путь ВНУТРИ КОНТЕЙНЕРА парсера, где будет храниться файл сессии Telegram.
# Этот путь должен совпадать с тем, что монтируется в DockerOperator в DAG.
TELEGRAM_SESSION_FOLDER_IN_TASK_CONTAINER=/app/session
# Путь на ХОСТ-МАШИНЕ к папке, которая будет смонтирована в контейнер для хранения сессии.
# Создайте эту папку на хосте, если ее нет.
HOST_PATH_TO_TG_SESSIONS_FOLDER=./airflow/session # Пример относительного пути

# --- GigaChat LLM API Configuration ---
# API-ключ для доступа к GigaChat. Используется скриптом summarizer.py.
GIGACHAT_API_KEY=YOUR_GIGACHAT_API_KEY_HERE
# (Опционально) Модель GigaChat для суммризации.
LLM_MODEL_NAME=GigaChat
# (Опционально) Максимальное количество новостей, передаваемых в LLM за раз.
MAX_NEWS_ITEMS_FOR_SUMMARY=15
# (Опционально) "Температура" для LLM, влияет на креативность ответа (0.0 - 1.0).
LLM_TEMPERATURE=0.7
# (Опционально) Максимальное количество токенов в ответе LLM.
LLM_MAX_TOKENS=700

# --- PostgreSQL Database for Parsing Results and Summaries ---
# Эти переменные используются всеми сервисами, которым нужен доступ к БД результатов:
# airflow-parser-task, airflow-summarizer-task, fastapi_service.
# Имя сервиса PostgreSQL в docker-compose.yml для БД результатов.
DB_HOST=postgres_results_db_service
# Внутренний порт PostgreSQL в контейнере БД результатов (стандартный 5432).
DB_PORT=5432
# Пользователь для подключения к БД результатов.
DB_USER=your_db_results_user
# Пароль для пользователя БД результатов.
DB_PASSWORD=your_db_results_password
# Имя базы данных для результатов парсинга и саммари.
DB_NAME=parsing_results_db
# (Опционально) Порт на хост-машине, который будет проброшен на внутренний порт 5432 контейнера БД результатов.
# Используется для внешнего доступа к БД, если необходимо (например, через pgAdmin).
DB_PORT_RESULTS_ON_HOST=5433

# --- Apache Airflow Configuration ---
# Эти переменные используются сервисами Airflow (scheduler, webserver, init).

# -- Airflow Metadata Database Connection --
# Имя сервиса PostgreSQL в docker-compose.yml для БД метаданных Airflow.
AIRFLOW_DB_HOST=postgres_airflow_db
# Внутренний порт PostgreSQL в контейнере БД метаданных Airflow (стандартный 5432).
AIRFLOW_DB_PORT=5432
# Пользователь для подключения к БД метаданных Airflow.
AIRFLOW_DB_USER=your_airflow_db_user
# Пароль для пользователя БД метаданных Airflow.
AIRFLOW_DB_PASSWORD=your_airflow_db_password
# Имя базы данных для метаданных Airflow.
AIRFLOW_DB_NAME=airflow_metadata_db
# (Опционально) Порт на хост-машине для проброса на внутренний порт БД метаданных Airflow.
AIRFLOW_DB_PORT_ON_HOST=5434

# Строка подключения к БД метаданных Airflow. Airflow использует ее для инициализации и работы.
# Формат: dialect+driver://username:password@host:port/database
# Замените ${...} на фактические значения ИЛИ оставьте так, если они определены выше и Docker Compose их подставит.
AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${AIRFLOW_DB_USER}:${AIRFLOW_DB_PASSWORD}@${AIRFLOW_DB_HOST}:${AIRFLOW_DB_PORT}/${AIRFLOW_DB_NAME}

# -- Airflow Core Settings --
# UID пользователя, под которым будут запускаться процессы Airflow внутри контейнеров.
# Помогает избежать проблем с правами доступа к смонтированным томам (например, папка dags).
# Для Linux/macOS: запустите `id -u` в терминале и используйте это значение. Для WSL часто 1000.
AIRFLOW_UID=1000
# Имя пользователя для входа в веб-интерфейс Airflow (будет создан при инициализации).
_AIRFLOW_WWW_USER_USERNAME=admin
# Пароль для пользователя веб-интерфейса Airflow.
_AIRFLOW_WWW_USER_PASSWORD=admin
# Ключ Fernet для шифрования чувствительных данных в Airflow (пароли подключений и т.д.).
# ОБЯЗАТЕЛЬНО СГЕНЕРИРУЙТЕ НОВЫЙ УНИКАЛЬНЫЙ КЛЮЧ:
# python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
# и вставьте его сюда.
AIRFLOW__CORE__FERNET_KEY=YOUR_UNIQUE_FERNET_KEY_HERE
# Тип исполнителя задач Airflow. LocalExecutor подходит для одного узла и простоты.
AIRFLOW__CORE__EXECUTOR=LocalExecutor
# Загружать ли примеры DAG'ов от Airflow. Обычно 'false' для пользовательских проектов.
AIRFLOW__CORE__LOAD_EXAMPLES=False
# Тег Docker-образа Airflow, который будет использоваться (см. Docker Hub apache/airflow).
AIRFLOW_IMAGE_TAG=2.8.1
# (Опционально) Порт на хост-машине для веб-интерфейса Airflow.
AIRFLOW_WEB_PORT=8080

# --- FastAPI Service Configuration ---
# Эти переменные используются сервисом fastapi_service.
# Путь к файлу channels.json на ХОСТ-МАШИНЕ. Этот файл будет смонтирован в контейнер.
# Убедитесь, что файл существует по этому пути.
CHANNELS_CONFIG_FILE_ON_HOST=./config/channels.json
# Путь к файлу channels.json ВНУТРИ КОНТЕЙНЕРА FastAPI. Используется приложением FastAPI.
# Должен совпадать с путем, куда монтируется CHANNELS_CONFIG_FILE_ON_HOST в docker-compose.yml.
CHANNELS_FILE_PATH_IN_CONTAINER=/app/config/channels.json
# (Опционально) Порт на хост-машине для проброса на внутренний порт FastAPI сервиса.
FASTAPI_PORT_ON_HOST=8000
# Уровень логирования для FastAPI приложения (например, INFO, DEBUG, WARNING, ERROR).
LOG_LEVEL=INFO

# --- Streamlit UI Configuration ---
# Эта переменная используется сервисом streamlit_service.
# Полный URL (включая схему http/https и порт) для подключения к FastAPI сервису.
# Внутри сети Docker это будет имя сервиса FastAPI (fastapi_api_service) и его внутренний порт (8000).
FASTAPI_BASE_URL=http://fastapi_api_service:8000
# (Опционально) Порт на хост-машине для проброса на внутренний порт Streamlit сервиса.
STREAMLIT_PORT_ON_HOST=8501

# --- Docker Image Tags for Airflow Tasks ---
# Эти переменные используются в Airflow DAG файле (например, telegram_dag.py)
# для указания, какой Docker-образ должен быть запущен DockerOperator'ом для каждой задачи.
# Образы должны быть предварительно собраны (например, через `docker build -t <имя_образа>:<тег> .`
# в соответствующей директории airflow/tasks/parser или airflow/tasks/summarizer).

# Имя и тег Docker-образа для задачи парсинга Telegram.
# Этот образ собирается из airflow/tasks/parser/Dockerfile.
PARSER_DOCKER_IMAGE_TAG=telegram_parser_task:latest

# Имя и тег Docker-образа для задачи суммризации постов.
# Этот образ собирается из airflow/tasks/summarizer/Dockerfile.
SUMMARIZER_DOCKER_IMAGE_TAG=telegram_summarizer_task:latest